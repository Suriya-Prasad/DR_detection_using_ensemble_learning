{"cells":[{"cell_type":"markdown","metadata":{"id":"XQaHv4Ee1FWm"},"source":["# **Importing and Extracting the dataset**"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13397,"status":"ok","timestamp":1679937152976,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"EawZ8KmbTVuZ"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.metrics import classification_report\n","from keras.applications import InceptionResNetV2, VGG19, Xception"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1679937152978,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"SSyyxTJ2U571"},"outputs":[],"source":["train_path = r'aptos_augmented_images_resized/train'\n","test_path = r'aptos_augmented_images_resized/test'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1679937152980,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"Nz9FmezHVrOa","outputId":"dafea44a-9cab-4822-be3b-36b8fcdb3984"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 8000 files belonging to 5 classes.\n","Using 7200 files for training.\n","Found 8000 files belonging to 5 classes.\n","Using 800 files for validation.\n","Found 2000 files belonging to 5 classes.\n"]}],"source":["training_data = tf.keras.utils.image_dataset_from_directory(train_path,validation_split=0.1,interpolation='area',image_size=(128,128),batch_size=8,subset='training',seed=42,color_mode='rgb')\n","validationData = tf.keras.utils.image_dataset_from_directory(train_path,validation_split=0.1,interpolation='area',image_size=(128,128),batch_size=8,subset='validation',seed=42,color_mode='rgb')\n","testing_data = tf.keras.utils.image_dataset_from_directory(test_path,interpolation='area',image_size=(128,128),shuffle=False,batch_size=16)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SJ5qjXn1zpOB"},"source":["# **Defining Models**\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10610,"status":"ok","timestamp":1679937163577,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"xByJ3T_K0cVB"},"outputs":[],"source":["inceptionResnet = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n","xception = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n","vgg = Xception(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gtb6tVOUyR2i"},"source":["# **AdaBoost**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oCWcIW1jyXDx"},"source":["<h2>Compute Error, Alpha and weight</h2>"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1679937163578,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"hDWVnaAif8Ll"},"outputs":[],"source":["# Compute error, alpha and weight\n","def compute_error(y, y_pred, w_i):\n","    '''\n","    Calculate the error rate of a weak classifier m. \n","    Arguments:\n","        y: actual target value\n","        y_pred: predicted value by weak classifier\n","        w_i: individual weights for each observation\n","\n","    '''\n","    return (sum(w_i * (np.not_equal(y, y_pred)).astype(int)))/sum(w_i)\n","\n","def compute_alpha(error):\n","    '''\n","    Calculate the weight of a weak classifier m in the majority vote of the final classifier.\n","    Arguments:\n","        error: error rate from weak classifier m\n","    '''\n","    return np.log((1 - error) / error)\n","\n","def update_weights(w_i, alpha, y, y_pred):\n","    ''' \n","    Update individual weights w_i after a boosting iteration.\n","    Arguments:\n","        w_i: individual weights for each observation\n","        y: actual target value\n","        y_pred: predicted value by weak classifier  \n","        alpha: weight of weak classifier used to estimate y_pred\n","    '''  \n","    return w_i * np.exp(alpha * (np.not_equal(y, y_pred)).astype(int))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2>Epoch vs Accuracy Graph</h2>"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1679937163578,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"2Gp2M-x8bGqq"},"outputs":[],"source":["# Function to plot epoch vs accuracy graph\n","\n","def print_history(model_history):\n","\n","  # summarize history for accuracy\n","  plt.plot(model_history.history['accuracy'])\n","  plt.plot(model_history.history['val_accuracy'])\n","  plt.title('model accuracy')\n","  plt.ylabel('accuracy')\n","  plt.xlabel('epoch')\n","  plt.legend(['train', 'validation'], loc='upper left')\n","  plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h2>Defining Adaboost Class</h2>"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1679937163579,"user":{"displayName":"19Z250 - SURIYA PRASAD P","userId":"03088647448879044303"},"user_tz":-330},"id":"897ZfzDnhi6U"},"outputs":[],"source":["# Define AdaBoost class\n","class AdaBoost:\n","    \n","    def __init__(self):\n","        self.alphas = []\n","        self.G_M = []\n","        self.M = None\n","        self.training_errors = []\n","        self.prediction_errors = []\n","\n","    def fit(self, training_data, M = 3):\n","        '''\n","        Fit model.\n","        Arguments:\n","            X: independent variables - array-like matrix\n","            y: target variable - array-like vector\n","            M: number of boosting rounds. Default is 3 - integer\n","        '''\n","        \n","        # Clear before calling\n","        self.alphas = [] \n","        self.training_errors = []\n","        self.M = M\n","\n","        test_labels = []\n","        for i in range(0,5):\n","            for j in range(0,400):\n","                test_labels.append(i)\n","        y = np.array(test_labels,dtype='int8')\n","\n","\n","        # Iterate over M weak classifiers\n","        for m in range(0, M):\n","            \n","            # Set weights for current boosting iteration\n","            if m == 0:\n","                w_i = np.ones(len(y)) * 1 / len(y)  # At m = 0, weights are all the same and equal to 1 / N\n","            else:\n","                # (d) Update w_i\n","                w_i = update_weights(w_i, alpha_m, y, y_pred)\n","            \n","\n","            # (a) Fit weak classifier and predict labels\n","            if (m % 3) == 0:\n","                  new_model = inceptionResnet\n","            elif (m % 3) == 1:\n","                  new_model = xception\n","            else:\n","                  new_model = vgg\n","\n","            # Creating rescaling layer add adding dense layers at the end of pretrained model to match the no. of classes \n","            G_m = tf.keras.Sequential()\n","            G_m.add(tf.keras.layers.Rescaling(scale=1./255))\n","            G_m.add(new_model)\n","            G_m.add(tf.keras.layers.Flatten())\n","            G_m.add(tf.keras.layers.Dense(500, activation='relu'))\n","            G_m.add(tf.keras.layers.Dense(100, activation='relu'))\n","            G_m.add(tf.keras.layers.Dense(5, activation='softmax'))\n","              \n","            G_m.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'],run_eagerly=True)\n","                  \n","            model_history = G_m.fit(training_data)\n","            print_history(model_history)\n","            pred = G_m.predict(training_data)\n","            y_pred = []\n","            for _ in pred:\n","              y_pred.append(np.argmax(_))\n","\n","            y_pred = np.array(y_pred)\n","\n","            \n","            self.G_M.append(G_m) # Save to list of weak classifiers\n","\n","            # (b) Compute error\n","            error_m = compute_error(y, y_pred, w_i)\n","            self.training_errors.append(error_m)\n","\n","            # (c) Compute alpha\n","            alpha_m = compute_alpha(error_m)\n","            self.alphas.append(alpha_m)\n","\n","        assert len(self.G_M) == len(self.alphas)\n","\n","    \n","    def predict(self, X):\n","        '''\n","        Predict using fitted model. \n","        Arguments:\n","            X: independent variables - array-like\n","        '''\n","\n","        # Initialise dataframe with weak predictions for each observation\n","        weak_preds = pd.DataFrame(index = range(len(X)), columns = range(self.M)) \n","\n","        # Predict class label for each weak classifier, weighted by alpha_m\n","        for m in range(self.M):\n","            y_pred_m = self.G_M[m].predict(X) * self.alphas[m]\n","            weak_preds.iloc[:,m] = y_pred_m\n","\n","        # Calculate final predictions\n","        y_pred = (1 * np.sign(weak_preds.T.sum())).astype(int)\n","\n","        return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7NZM6mGOhmz8","outputId":"b2743d6f-6835-4d48-d7eb-b4e07a5d043e"},"outputs":[],"source":["ab = AdaBoost()\n","\n","# train_labels = np.array([])\n","# for images, labels in training_data:\n","#     train_labels = np.concatenate((train_labels,labels.numpy()),axis=0)\n","\n","# train_labels.astype(int)\n","\n","# len(train_data)\n","# # len(train_labels)\n","\n","ab.fit(training_data,M = 3)\n","\n","# Predict on test set\n","# y_pred = ab.predict(validationData)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
