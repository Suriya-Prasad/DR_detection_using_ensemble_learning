{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing and Extracting the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'aptos_augmented_images_resized/train'\n",
    "test_path = r'aptos_augmented_images_resized/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 5 classes.\n",
      "Using 7200 files for training.\n",
      "Found 8000 files belonging to 5 classes.\n",
      "Using 800 files for validation.\n",
      "Found 2000 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data = tf.keras.utils.image_dataset_from_directory(train_path,validation_split=0.1,interpolation='area',image_size=(128,128),batch_size=16,subset='training',seed=42,color_mode='rgb')\n",
    "validationData = tf.keras.utils.image_dataset_from_directory(train_path,validation_split=0.1,interpolation='area',image_size=(128,128),batch_size=16,subset='validation',seed=42,color_mode='rgb')\n",
    "testing_data = tf.keras.utils.image_dataset_from_directory(test_path,interpolation='area',image_size=(128,128),shuffle=False,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating list for y_test\n",
    "\n",
    "test_labels = []\n",
    "for i in range(0,5):\n",
    "    for j in range(0,400):\n",
    "        test_labels.append(i)\n",
    "y_test = np.array(test_labels,dtype='int8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building and Training Individual Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_building(base_model):\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Rescaling(scale=1./255))\n",
    "    model.add(tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"))\n",
    "    model.add(tf.keras.layers.RandomRotation(0.2))\n",
    "    model.add(base_model)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model):\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'],run_eagerly=True)\n",
    "    model_history = model.fit(training_data,shuffle=True,epochs=5,validation_data=validationData)\n",
    "\n",
    "    return model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,name):\n",
    "    model.save('models/' + name + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predictions of Individual Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model):\n",
    "    return model.predict(testing_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_vs_accuracy(model_history):\n",
    "    \n",
    "    plt.plot(model_history.history['accuracy'])\n",
    "    plt.plot(model_history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(y_pred):\n",
    "\n",
    "    return classification_report(y_true=y_test,y_pred=y_pred,labels=[0,1,2,3,4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(actual, predicted, class_labels):\n",
    "\n",
    "    tn = np.zeros(len(class_labels))\n",
    "    fp = np.zeros(len(class_labels))\n",
    "    tp = np.zeros(len(class_labels))\n",
    "    fn = np.zeros(len(class_labels))\n",
    "    specificity = np.zeros(len(class_labels))\n",
    "\n",
    "    for i, c in enumerate(class_labels):\n",
    "        actual_c = actual == c\n",
    "        predicted_c = predicted == c\n",
    "        tn[i] = np.sum(np.logical_and(actual_c == False, predicted_c == False))\n",
    "        fp[i] = np.sum(np.logical_and(actual_c == False, predicted_c == True))\n",
    "        tp[i] = np.sum(np.logical_and(actual_c == True, predicted_c == True))\n",
    "        fn[i] = np.sum(np.logical_and(actual_c == True, predicted_c == False))\n",
    "        specificity[i] = tn[i] / (tn[i] + fp[i])\n",
    "\n",
    "    return tn, fp, tp, fn, specificity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inseption Resnet V2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivr2 = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(input_shape=[256,256]+[3],weights= 'imagenet' ,include_top=False)\n",
    "ivr2 = model_building(ivr2)\n",
    "ivr2_history = model_training(ivr2)\n",
    "ivr2_predictions = model_prediction(ivr2)\n",
    "save_model(ivr2,'IRv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vs_accuracy(ivr2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(ivr2_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_ivr2 = tf.math.confusion_matrix(y_test,ivr2_predictions)\n",
    "cm_ivr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, tp, fn, specificity = calculate_metrics(y_test, ivr2_predictions, [0,1,2,3,4])\n",
    "print('Inception Resnet V2 Specificity\\n\\n',specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_ivr2,fmt='d',annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Xception**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = tf.keras.applications.xception.Xception(input_shape=[256,256]+[3],weights= 'imagenet' ,include_top=False)\n",
    "xception = model_building(xception)\n",
    "xception_history = model_training(xception)\n",
    "xception_predictions = model_prediction(xception)\n",
    "save_model(xception,'Xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vs_accuracy(xception_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(xception_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xception = tf.math.confusion_matrix(y_test,xception_predictions)\n",
    "cm_xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, tp, fn, specificity = calculate_metrics(y_test, xception_predictions, [0,1,2,3,4])\n",
    "print('Xception Specificity\\n\\n',specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_xception,fmt='d',annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VGG19**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.vgg19.VGG19(input_shape=[256,256]+[3],weights= 'imagenet' ,include_top=False)\n",
    "vgg = model_building(vgg)\n",
    "vgg_history = model_training(vgg)\n",
    "vgg_predictions = model_prediction(vgg)\n",
    "save_model(vgg,'VGG19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vs_accuracy(vgg_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(vgg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_vgg = tf.math.confusion_matrix(y_test,vgg_predictions)\n",
    "cm_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, tp, fn, specificity = calculate_metrics(y_test, vgg_predictions, [0,1,2,3,4])\n",
    "print('VGG19 Specificity\\n\\n',specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_vgg,fmt='d',annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Resnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.vgg19.VGG19(input_shape=[256,256]+[3],weights= 'imagenet' ,include_top=False)\n",
    "resnet = model_building(resnet)\n",
    "resnet_history = model_training(resnet)\n",
    "resnet_predictions = model_prediction(resnet)\n",
    "save_model(resnet,'Resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vs_accuracy(resnet_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(resnet_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_resnet = tf.math.confusion_matrix(y_test,resnet_predictions)\n",
    "cm_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, tp, fn, specificity = calculate_metrics(y_test, resnet_predictions, [0,1,2,3,4])\n",
    "print('Resnet Specificity\\n\\n',specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_resnet,fmt='d',annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Densenet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = tf.keras.applications.vgg19.VGG19(input_shape=[256,256]+[3],weights= 'imagenet' ,include_top=False)\n",
    "densenet = model_building(densenet)\n",
    "densenet_history = model_training(densenet)\n",
    "densenet_predictions = model_prediction(densenet)\n",
    "save_model(densenet,'Densenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vs_accuracy(densenet_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(densenet_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_densenet = tf.math.confusion_matrix(y_test,densenet_predictions)\n",
    "cm_densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, tp, fn, specificity = calculate_metrics(y_test, densenet_predictions, [0,1,2,3,4])\n",
    "print('Densenet Specificity\\n\\n',specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_densenet,fmt='d',annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
